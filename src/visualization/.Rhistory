legend.position = "bottom")
F14
F15 <- nyt_2candidates %>% mutate(date = as.Date(date)) %>%
group_by(date) %>%
ggplot(aes(date, tone, color = author)) +
geom_point() +  geom_smooth() +
facet_wrap(~ author, scales = "free_y") +
geom_vline(xintercept = as.numeric(as.Date('2016-07-21')), size = 1, alpha = 0.3) +
geom_vline(xintercept = as.numeric(as.Date('2016-07-28')), size = 1, alpha = 0.3) +
geom_vline(xintercept = as.numeric(as.Date('2016-11-08')), size = 1, alpha = 0.3) +
geom_vline(xintercept = as.numeric(as.Date('2017-01-20')), size = 1, alpha = 0.3) +
labs(x="Date", y="Tone") +
theme_minimal() +
ggtitle(expression(atop(bold("F15 the Tone Difference across Columnists over time"),
atop(italic("Facet with Columnists"), "")))) +
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 0.5, hjust = -0.3))
F15
# Identify associations with trump and clinton
## Create associations with "trump"
associationsDT <- findAssocs(nyt_tdm, c("trump"), 0.2)
### Select the Top 50 associations
associationsDT$trump <- associationsDT$trump[1:50]
### Create associations_df
associationsDT_df <- list_vect2df(associationsDT)[, 2:3]
colnames(associationsDT_df) <- c("Association","Score")
## Create associations with "clinton"
associationsHC <- findAssocs(nyt_tdm, c("clinton"), 0.2)
### Select the Top 50 associations
associationsHC$clinton <- associationsHC$clinton[1:50]
### Create associations_df
associationsHC_df <- list_vect2df(associationsHC)[, 2:3]
colnames(associationsHC_df) <- c("Association","Score")
## Plot the associations_df values
### too many asscociations
F6.1 <- ggplot(associationsDT_df, aes(y = associationsDT_df[, 1])) +
geom_point(aes(x = associationsDT_df[, 2]),
data = associationsDT_df, size = 3) +
xlab("Word Association") + ylab(NULL) +
ggtitle(" F6 Word Assocation with `Trump'") + theme_bw()+
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 1, hjust = 0.5))
F6.1
devtools::install_github("rstudio/leaflet")
library(leaflet)
F3 <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf)  %>%
ggplot(aes(x = reorder(term, tf_idf), y = tf_idf, fill = columnist)) +
geom_bar(stat = "identity") + coord_flip() +
facet_wrap(~columnist, scales="free_y") +
xlab("Frequent Term by columnist") + ylab("TF-IDF Score") + theme_hc() +
ggtitle("F3 Frequent Terms by Columnist") +
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 3, hjust = 0.4))
F3
View(us_restaurant)
library("lubridate")
distinct(us_restaurant$city)
table(us_restaurant$city)
b <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf) %>%
mutate(key = 1:10)  %>%
arrange(author,desc(tf_idf))  %>%
ungroup()  %>%
mutate(idx_label = 50:1)
business <- read.csv('../../data/processed/us_restaurants.csv')
business <- read.csv("~/Documents/qmss_g5069_yelp_challenge/data/processed/us_restaurants.csv")
library(tidyverse)
library(tidytext)
library(tm)
library(qdap)
library(rvest)
library(quanteda)
load("~/Documents/QMSS-G4063-Data-Visualization/Assignments/Assignment 3/nytimes_oped_corpus.rda")
nyt_df <- corpus$documents
# only pick month and year
nyt_df$Month_Yr <- format(as.Date(nyt_df$date), "%Y-%m")
nyt_df <- unite(nyt_df, newcol, c(Month_Yr, author), remove=FALSE)
nyt_source <- DataframeSource(nyt_df[, c("texts", "author","Month_Yr", "newcol")])
nyt_corpus <- VCorpus(nyt_source)
meta(nyt_corpus, type = "local", tag = "columnist") <- nyt_df$author
meta(nyt_corpus, type = "local", tag = "Month_Yr") <- nyt_df$Month_Yr
# Tokenizing the corpus
## bulid own stop words and then remove
new_stops <- c("and","andr","one","say","just","year","also","even","now","said", "like", "get", "think", stopwords("english"))
removeNumPunct <- function(x){gsub("[^[:alpha:][:space:]]*", "", x)}
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(replace_symbol))
corpus <- tm_map(corpus, removeWords, c(new_stops))  # removing stop words
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))
return(corpus)
}
## Apply your customized function to the nyt_corpus: nyt_clean
nyt_clean <- clean_corpus(nyt_corpus)
# Stemming the corpus
library(SnowballC)
## Stem all words
nyt_stemmed <- tm_map(nyt_clean, stemDocument)
# Prpare for viz
## Make DTM
nyt_dtm <- DocumentTermMatrix(nyt_stemmed)
nyt_dtm_m <- as.matrix(nyt_dtm)
## Make TDM
nyt_tdm <- TermDocumentMatrix(nyt_stemmed)
nyt_tdm_m <- as.matrix(nyt_tdm)
## add columnist in
nyt_tdm$dimnames$Docs <- nyt_df$newcol
## Tidying Objects
nyt_td <- tidy(nyt_tdm)
nyt_td$date <- substr(nyt_td$document,1,7)
nyt_td$columnist <- substr(nyt_td$document,9,nchar(nyt_td$document))
theme_gg <- function(ggplot) {
theme_bw(base_size=base_size, base_family=base_family) %+replace%
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 1, hjust = 0.5))
}
# Frequent Terms
library(ggplot2)
library(ggthemes)
F1 <-  nyt_td %>%
group_by(term) %>%
summarise(n = sum(count)) %>%
top_n(n = 20, wt = n)  %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n)) +
geom_bar(stat = "identity", fill = "deepskyblue2") +
xlab(NULL) +  coord_flip() + theme_minimal()+
labs(y = "Total Number", x ="Terms") +
ggtitle("F1 Frequent Terms")+
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 1, hjust = 0.5))
F1
# Bind the TF,DF, and IDF frequency
# of a tidy text dataset to the dataset
nyt_tf_idf <-  nyt_td %>%
bind_tf_idf(term, columnist, count) %>%
arrange(desc(tf_idf))
# Most frequent terms by columnist
F2 <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 1, wt = tf_idf)  %>%
ggplot(aes(x = reorder(term, tf_idf), y = tf_idf)) +
geom_bar(aes(fill = columnist), stat = "identity") +
geom_text(aes(label = columnist, x = term, y = 0.005), color = "black", hjust = 2, nudge_x = 0.05) +
xlab(NULL) +  coord_flip() + theme_minimal()+
labs(y = "TF-IDF Score", x ="Terms") +
ggtitle("F2 Frequent Terms by Columnist")+
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 1, hjust = 0.5),
legend.position = "top")
F2
F3 <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf)  %>%
ggplot(aes(x = reorder(term, tf_idf), y = tf_idf, fill = columnist)) +
geom_bar(stat = "identity") + coord_flip() +
facet_wrap(~columnist, scales="free_y") +
xlab("Frequent Term by columnist") + ylab("TF-IDF Score") + theme_hc() +
ggtitle("F3 Frequent Terms by Columnist") +
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 3, hjust = 0.4))
F3
b <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf) %>%
mutate(key = 1:10)  %>%
arrange(author,desc(tf_idf))  %>%
ungroup()  %>%
mutate(idx_label = 50:1)
?mutate
?key
b <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf) %>%
mutate(key = 1:10)  %>%
arrange(columnist, desc(tf_idf))  %>%
ungroup()  %>%
mutate(idx_label = 50:1)
b <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf) %>%
mutate(key = 1:11)  %>%
arrange(columnist, desc(tf_idf))  %>%
ungroup()  %>%
mutate(idx_label = 50:1)
b <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf) %>%
mutate(key = 1:15)  %>%
arrange(columnist, desc(tf_idf))  %>%
ungroup()  %>%
mutate(idx_label = 50:1)
?mutate
packages <- c("network","ggnetwork","ergm","igraph","ggraph","tweenr","geomnet","GGally","statnet","sna","rsvg","svglite","networkD3","twitteR","ROAuth","httr","jsonlite","intergraph","ggrepel","svgPanZoom","SVGAnnotation","DT")
packages <- lapply(packages, FUN = function(x) {
if(!require(x, character.only = TRUE)) {
install.packages(x)
library(x, character.only = TRUE)
}
})
F14 <- nyt_2candidates %>%
ggplot(aes(x= as.Date(date), tone, color = author)) +
geom_point(size = 2) +  geom_smooth(se=FALSE) +
geom_vline(xintercept = as.numeric(as.Date('2016-07-21')), size = 2, alpha = 0.3) +
geom_vline(xintercept = as.numeric(as.Date('2016-07-28')), size = 2, alpha = 0.3) +
geom_vline(xintercept = as.numeric(as.Date('2016-11-08')), size = 10, alpha = 0.3) +
geom_vline(xintercept = as.numeric(as.Date('2017-01-20')), size = 10, alpha = 0.3) +
labs(x="Date", y="Tone") +
theme_minimal() +
ggtitle(expression(atop(bold(" F14 Difference of the Tone between Two Candidates over Time"),
atop(italic("with Annotation of Political Events"), "")))) +
theme(plot.title = element_text(face = "bold", color = "black", size = 14, vjust = 0.5, hjust = 0.5),
legend.position = "bottom") + geom_vline(xintercept = c(7.75, 11.27, 13.6), lty=2, color ="grey") + annotate("text", x = c(10.58, 12.68, 14.78), y = 0.09, adj=1, family="serif", label = c("Democratic & Republican \n Conventions", "Election Day", "Inaugration"))
F3 <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf)  %>%
ggplot(aes(x = reorder(term, tf_idf), y = tf_idf, fill = columnist)) +
geom_bar(stat = "identity") + coord_flip() +
facet_wrap(~columnist, scales="free_y") +
xlab("Frequent Term by columnist") + ylab("TF-IDF Score") + theme_hc() +
ggtitle("F3 Frequent Terms by Columnist") +
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 3, hjust = 0.4))
F3
b <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf) %>%
mutate(key = 1:11)  %>%
arrange(columnist, desc(tf_idf))  %>%
ungroup()  %>%
mutate(idx_label = 50:1)
View(nyt_tf_idf)
b <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf)
View(nyt_tf_idf)
View(b)
b <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf) %>%
mutate(key = 1:10)  %>%
arrange(columnist, desc(tf_idf))  %>%
ungroup()  %>%
mutate(idx_label = 59:1)
F3 <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf)  %>%
ggplot(aes(x = reorder(term, tf_idf), y = tf_idf, fill = columnist)) +
geom_bar(stat = "identity") + coord_flip() +
facet_wrap(~columnist, scales="free_y") +
xlab("Frequent Term by columnist") + ylab("TF-IDF Score") + theme_hc() +
ggtitle("F3 Frequent Terms by Columnist") +
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 3, hjust = 0.4))
F3
View(nyt_tf_idf)
## merge documents
colnames(nyt_DT2)[16] <- "tone"
# Difference in the tone of texts
## Hu & Liu Dictionary
pos <- read.table("~/Documents/QMSS-G4063-Data-Visualization/Assignments/Assignment 3/dictionaries/positive-words.txt", as.is=T)
neg <- read.table("~/Documents/QMSS-G4063-Data-Visualization/Assignments/Assignment 3/dictionaries/negative-words.txt", as.is=T)
## function to do simply arithmetic
sentiment <- function(words=c("great america")){
require(quanteda)
tok <- quanteda::tokenize(words)
pos.count <- sum(tok[[1]]%in%pos[,1])
neg.count <- sum(tok[[1]]%in%neg[,1])
out <- (pos.count - neg.count)/(pos.count+neg.count)
return(out)
}
### add the column of tone of texts about Trump into nyt_DT
tone_DT <- matrix(0,222,1)
for(i in 1:222){
tone_DT[i,1] <- sentiment(nyt_DT[i,1])
}
library(tidyverse)
library(tidytext)
library(tm)
library(qdap)
library(rvest)
library(quanteda)
load("~/Documents/QMSS-G4063-Data-Visualization/Assignments/Assignment 3/nytimes_oped_corpus.rda")
nyt_df <- corpus$documents
# only pick month and year
nyt_df$Month_Yr <- format(as.Date(nyt_df$date), "%Y-%m")
nyt_df <- unite(nyt_df, newcol, c(Month_Yr, author), remove=FALSE)
nyt_source <- DataframeSource(nyt_df[, c("texts", "author","Month_Yr", "newcol")])
nyt_corpus <- VCorpus(nyt_source)
meta(nyt_corpus, type = "local", tag = "columnist") <- nyt_df$author
meta(nyt_corpus, type = "local", tag = "Month_Yr") <- nyt_df$Month_Yr
# Tokenizing the corpus
## bulid own stop words and then remove
new_stops <- c("and","andr","one","say","just","year","also","even","now","said", "like", "get", "think", stopwords("english"))
removeNumPunct <- function(x){gsub("[^[:alpha:][:space:]]*", "", x)}
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(replace_symbol))
corpus <- tm_map(corpus, removeWords, c(new_stops))  # removing stop words
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(removeNumPunct))
return(corpus)
}
## Apply your customized function to the nyt_corpus: nyt_clean
nyt_clean <- clean_corpus(nyt_corpus)
# Stemming the corpus
library(SnowballC)
## Stem all words
nyt_stemmed <- tm_map(nyt_clean, stemDocument)
# Prpare for viz
## Make DTM
nyt_dtm <- DocumentTermMatrix(nyt_stemmed)
nyt_dtm_m <- as.matrix(nyt_dtm)
## Make TDM
nyt_tdm <- TermDocumentMatrix(nyt_stemmed)
nyt_tdm_m <- as.matrix(nyt_tdm)
## add columnist in
nyt_tdm$dimnames$Docs <- nyt_df$newcol
## Tidying Objects
nyt_td <- tidy(nyt_tdm)
nyt_td$date <- substr(nyt_td$document,1,7)
nyt_td$columnist <- substr(nyt_td$document,9,nchar(nyt_td$document))
theme_gg <- function(ggplot) {
theme_bw(base_size=base_size, base_family=base_family) %+replace%
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 1, hjust = 0.5))
}
# Frequent Terms
library(ggplot2)
library(ggthemes)
F1 <-  nyt_td %>%
group_by(term) %>%
summarise(n = sum(count)) %>%
top_n(n = 20, wt = n)  %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n)) +
geom_bar(stat = "identity", fill = "deepskyblue2") +
xlab(NULL) +  coord_flip() + theme_minimal()+
labs(y = "Total Number", x ="Terms") +
ggtitle("F1 Frequent Terms")+
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 1, hjust = 0.5))
F1
# Bind the TF,DF, and IDF frequency
# of a tidy text dataset to the dataset
nyt_tf_idf <-  nyt_td %>%
bind_tf_idf(term, columnist, count) %>%
arrange(desc(tf_idf))
# Most frequent terms by columnist
F2 <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 1, wt = tf_idf)  %>%
ggplot(aes(x = reorder(term, tf_idf), y = tf_idf)) +
geom_bar(aes(fill = columnist), stat = "identity") +
geom_text(aes(label = columnist, x = term, y = 0.005), color = "black", hjust = 2, nudge_x = 0.05) +
xlab(NULL) +  coord_flip() + theme_minimal()+
labs(y = "TF-IDF Score", x ="Terms") +
ggtitle("F2 Frequent Terms by Columnist")+
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 1, hjust = 0.5),
legend.position = "top")
F2
F3 <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf)  %>%
ggplot(aes(x = reorder(term, tf_idf), y = tf_idf, fill = columnist)) +
geom_bar(stat = "identity") + coord_flip() +
facet_wrap(~columnist, scales="free_y") +
xlab("Frequent Term by columnist") + ylab("TF-IDF Score") + theme_hc() +
ggtitle("F3 Frequent Terms by Columnist") +
theme(plot.title = element_text(face = "bold", color = "black", size = 16, vjust = 3, hjust = 0.4))
F3
b <- nyt_tf_idf %>%
group_by(columnist) %>%
top_n(n = 10, wt = tf_idf) %>%
mutate(key = 1:10)  %>%
arrange(columnist, desc(tf_idf))  %>%
ungroup()  %>%
mutate(idx_label = 50:1)
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) + geom_col(position = "fill")
library(tidyverse)
# Importing the data
library(readxl)
edu_wide <- read_excel("US_counties_data/Education.xls", skip=5)
edu_wide <- edu_wide[,-grep("x_", names(edu_wide))]
edu_wide <- as.data.frame(edu_wide)
# Convert from wide to long
library(reshape)
edu_long <- stats::reshape(edu_wide,
varying = names(edu_wide)[4:23],
direction = "long",
idvar = c("fips_code"),
timevar = "year",
sep = "_")
# Identify states and counties
edu_long$area_type <-  ifelse(as.numeric(substr(edu_long$fips_code,3,5))!=0,"county","state")
edu_long$area_type <-  ifelse(as.numeric(substr(edu_long$fips_code,1,5))==0,"country",edu_long$area_type)
data1 <- edu_long %>%
filter(area_type == "country")
data1 <- data1[,4:8]
data1 <- gather(data1,"educL", "Perct", 2:5) # gather columns into rows
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) + geom_col(position = "fill")
F1
F2 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) + geom_col(position = "dodge")
F2
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year")
F1
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year") +
ggplotly(F1)
library(plotly)
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year") +
ggplotly(F1)
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year")
ggplotly(F1)
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year")
ggplotly(F1)
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year")
F1
ggplotly(F1)
F2 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "dodge")
F2
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year") +
scale_x_discrete(breaks=c("1970","1980","1990", "2000","2017"),
labels=c("1970","1980","1990", "2000","2017""))
F1
F2 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "dodge")
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year") +
scale_x_discrete(breaks=c("1970","1980","1990", "2000","2017"),
labels=c("1970","1980","1990", "2000","2017"))
F1
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year") +
scale_x_discrete(
labels=c("1970","1980","1990", "2000","2017"))
F1
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year") +
scale_x_continuous(breaks=c("1970","1980","1990", "2000","2017"),
labels=c("1970","1980","1990", "2000","2017"))
F1
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year") +
scale_x_discrete(breaks=c("1970","1980","1990","2000","2017"),
labels=c("1970","1980","1990", "2000","2017"))
F1
F1 <- data1 %>%
plot_ly(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year") +
scale_x_discrete(breaks=c("1970","1980","1990","2000","2017"),
labels=c("1970","1980","1990", "2000","2017"))
F1 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "fill") +
xlab("Year") +
scale_x_discrete(breaks=c("1970","1980","1990","2000","2017"),
labels=c("1970","1980","1990", "2000","2017"))
F1
F2 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "dodge")
F2
ggplotly(F2)
F2 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "dodge")
ggplotly(F2)
F2
F2 <- data1 %>%
ggplot(aes(x = year, y = Perct, fill = educL)) +
geom_col(position = "dodge")
F2
ggplotly(F2)
F2
ggplotly(F2)
F1
ggplotly(F1)
library(plotly)
ggplotly(F1)
